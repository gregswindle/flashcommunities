# `flash-communities`
> An art collective dedicated to generating spontaneous events designed to inspire a sense of humanistic unity among strangers.

## Table of contents
<!-- TOC depthFrom:2 depthTo:4 withLinks:1 updateOnSave:1 orderedList:0 -->

- [Table of contents](#table-of-contents)
- [1. Epic story: facilitate flash-communities](#1-epic-story-facilitate-flash-communities)
- [2. Background](#2-background)
- [3. Initial vision and purpose](#3-initial-vision-and-purpose)
	- [3.1. Early iterations as art installations](#31-early-iterations-as-art-installations)
- [4. Next steps](#4-next-steps)
	- [4.1. Prioritize scope](#41-prioritize-scope)
	- [4.2. Define necessary tools, technologies, and skillsets](#42-define-necessary-tools-technologies-and-skillsets)
	- [4.3. Design solid privacy protection](#43-design-solid-privacy-protection)
- [5. License](#5-license)

<!-- /TOC -->

## 1. Epic story: facilitate flash-communities

As a Humanist,<br>
I want to facilitate rapid communal bonds using personal, data-mined sounds and imagery<br>
In order to inspire spontaneous social unity among strangers.<br>

## 2. Background

Unlike flashmobs - quick, public assemblies of people who engage in coordinated _performances_ intended for outward-facing audiences - **flash-communities** are introverted events akin to family reunions, where members share a pot-luck of music, tweets, posts, videos, and images (all of which are anonymously and automatically data-mined from mobile devices). Projects focussed on `flash-communities` iteratively explore and experiment with  the formation of minimally to non-hierarchical groups for goal-oriented enterprises.

## 3. Initial vision and purpose

I'm still working out a potential audio-visual product/experience, but here's where I am so far.

Similar to some of [Olafur Eliasson](https://en.wikipedia.org/wiki/Olafur_Eliasson)'s work exploring humanity's relationship with geometry and space, and how these relationships affect the meaning of "public," `flash-communities` function to classify and transmit social media events as semantic networks that connect the participants directly and indirectly via shared nodes of emotion, proximity, and time.

My goal is to plot personal events (starting with social media "activity logs") to plot graphs expressed by the constituent sounds and images of the very media shared. Initial iterations of such graphs will likely culminate into a harmonic drone of sound based on the strongest edges within each graph, slowed and sustained as until a shared chorus has been achieved.

> #### `flash-communities` as [Temporary Autonomous Zones (TAZ)](https://en.wikipedia.org/wiki/Temporary_Autonomous_Zone)?
> I'm revisiting the concepts behind the formation of TAZs, especially with "Music as an Organizational Principle." Like TAZs, `flash-community` events and projects share similar goals: to expose the invisible, unexamined emotional and intellectual nodes that bind and separate us as a means for identifying more cooperative pathways.

### 3.1. Early iterations as art installations

Participants enter a room (inspired/informed by the work of Olafur Eliasson) and:

- [ ] 1. Beacons identify participants and queue their prepared media
- [ ] 2. Images begin to float from the floor to the ceiling, moving upward in chronological order
- [ ] 3. Intersections, unions, and associations among participants' data are sonically mapped and processed  to create tones and chords
- [ ] 4. All media and song merge harmonically overhead to generate a unique "noosphere"

> ##### :iphone: Prerequisite data-mining
>
> As currently conceived, flash-communities will require a mobile app that participants must install and (transparently) link to their social media accounts. The mobile app anonymously gathers favorite songs, recent images, and other personal data in order to generate a coordinated presentation of meaningful life-events and facts to be shared and orchestrated during a flash-community event.

## 4. Next steps

- [ ] Story-board a "best case" example
- [ ] Identify the type of graph best suited to cumulative, ambient tonal resolution, starting with:
    - [Hypergraphs](https://en.wikipedia.org/wiki/Hypergraph), whose ["families of sets"](https://en.wikipedia.org/wiki/Family_of_sets) could be easily mapped to sounds and images
    - [Conceptual graphs](https://en.wikipedia.org/wiki/Conceptual_graph)
- [ ] Design the data store and its associations
- [ ] Map audio and visuals (preferably in Key)
- [ ] Identify and design visual surfaces that reflect or project images
- [ ] Budget the whole damn thing :money_with_wings:

### 4.1. Prioritize scope

- Based on feasibility and resources, determine whether to proceed.
- Gather materials for a prototype
- Build app and backend (will this require AI or machining learning?)
- Conduct tests

### 4.2. Define necessary tools, technologies, and skillsets

- [ ] Mobile app that mines social media audio-visual likes
- [ ] BaaS to store data
- [ ] Async backend agents that classify the media:
   - [ ] Chronologically
   - [ ] Geo-spatially
   - [ ] Music by
      - [ ] Genre
      - [ ] Key
      - [ ] ...
- [ ] Data-store, backend APIs, etc.

### 4.3. Design solid privacy protection

Privacy is paramount, and I will not proceed unless I feel confident about a data store and security risks.

Participants should be able to choose what *not* to be shared.

## 5. License

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
